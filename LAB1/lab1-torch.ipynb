{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 70>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     78\u001B[0m y_test \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mLongTensor(y_test)\n\u001B[1;32m     79\u001B[0m model \u001B[38;5;241m=\u001B[39m BayesClassifier(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m---> 80\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{:.4f}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(model\u001B[38;5;241m.\u001B[39maccuracy(x_test, y_test)))\n\u001B[1;32m     82\u001B[0m model\u001B[38;5;241m.\u001B[39mplot(x_test, y_test)\n",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36mBayesClassifier.fit\u001B[0;34m(self, x, y, epochs, lr)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m     50\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 51\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     53\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36mBayesClassifier.loss\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mloss\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y):\n\u001B[0;32m---> 44\u001B[0m     log_posterior \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39mtorch\u001B[38;5;241m.\u001B[39mmean(log_posterior[torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mlen\u001B[39m(y)), y])\n",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36mBayesClassifier.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     27\u001B[0m log_prior \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_prior\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     28\u001B[0m log_prior \u001B[38;5;241m=\u001B[39m log_prior \u001B[38;5;241m-\u001B[39m torch\u001B[38;5;241m.\u001B[39mlogsumexp(log_prior, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 29\u001B[0m log_likelihood \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m (log_var \u001B[38;5;241m+\u001B[39m ((\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmean\u001B[49m) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m/\u001B[39m torch\u001B[38;5;241m.\u001B[39mexp(log_var))\n\u001B[1;32m     30\u001B[0m log_likelihood \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(log_likelihood, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     31\u001B[0m log_posterior \u001B[38;5;241m=\u001B[39m log_likelihood \u001B[38;5;241m+\u001B[39m log_prior\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Bayes Cliassifier for Iris Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = './dataset/iris.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
